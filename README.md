Advanced Financial Report Analyzer
This project is an advanced Retrieval-Augmented Generation (RAG) application designed to answer questions about financial reports. It leverages a sophisticated pipeline including Hypothetical Document Embeddings (HyDE) and a reranker to provide highly accurate, context-aware answers grounded in the source documents.

The application is built with a modular architecture and features a user-friendly web interface created with Streamlit, allowing users to upload their own financial reports and start querying them immediately.
<img width="870" height="1006" alt="image" src="https://github.com/user-attachments/assets/c80b7362-a4b3-4b22-9fe5-040482129940" />
<img width="747" height="591" alt="image" src="https://github.com/user-attachments/assets/ff6f66cb-73ae-4709-944f-245f071db6f4" />

Features
Advanced RAG Pipeline: Goes beyond simple vector search to provide more relevant and accurate answers.

HyDE (Hypothetical Document Embeddings): Generates a hypothetical answer to the user's query first, using this richer context to perform a more effective vector search.

Reranker Integration: Retrieves a larger set of initial documents and then uses a sophisticated reranker (Cohere) to re-order them based on true relevance to the original query.

High-Quality Document Processing: Uses unstructured to intelligently parse complex PDFs, including tables and multi-column layouts.

Efficient Embedding and Storage: Leverages NVIDIA's high-performance embedding models and stores vectors locally using ChromaDB.

Fast Inference: Powered by the Groq API for near-instant LLM responses for both HyDE and final answer generation.

Interactive Web Interface: Built with Streamlit, allowing for easy interaction and dynamic document uploads.

Architecture Overview
The project is divided into two main pipelines: Ingestion and Querying.

1. Ingestion Pipeline
<!-- Optional: Add a diagram -->

Load & Parse: A PDF document is loaded and parsed using unstructured to handle complex layouts.

Chunk: The extracted text is split into smaller, semantically coherent chunks using RecursiveCharacterTextSplitter.

Embed: Each chunk is converted into a numerical vector using an NVIDIA embedding model.

Store: The chunks and their corresponding vectors are stored in a local ChromaDB vector database.

2. Query Pipeline
<!-- Optional: Add a diagram -->

Query: The user asks a question through the Streamlit interface.

HyDE Generation: A hypothetical, ideal answer is generated by a fast LLM (via Groq).

Vector Search: The hypothetical answer is embedded and used to retrieve the top N most similar documents from ChromaDB.

Rerank: The retrieved documents are reranked by a Cohere reranker based on their relevance to the original user query, narrowing them down to the top K most relevant.

Final Answer Generation: The original query and the top K reranked documents are passed to a final LLM (via Groq) to synthesize an accurate, grounded answer.

Technologies Used
Backend: Python

Web UI: Streamlit

LLM APIs: Groq (for Llama 3), NVIDIA (for Embeddings), Cohere (for Reranking)

Core Libraries:

langchain: For orchestrating the RAG pipeline.

unstructured[pdf]: For robust PDF parsing.

chromadb: For local vector storage and search.

streamlit: For the web application interface.

External Dependencies:

Poppler: For PDF rendering and processing.

Tesseract: For Optical Character Recognition (OCR) in image-based PDFs.

Setup and Installation
Prerequisites
You must have the following external dependencies installed on your system and available in your system's PATH.

Poppler: A PDF rendering library.

Installation guide for Windows

Tesseract-OCR: An optical character recognition engine.

Installation guide for Windows

Important: During installation, ensure you add Tesseract to your system's PATH.
